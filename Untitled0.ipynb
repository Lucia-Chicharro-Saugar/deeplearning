{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAFxUAqJG5YkHzZg8bdZ7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucia-Chicharro-Saugar/deeplearning/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-T6YiqWDrDU",
        "outputId": "553e8326-01b7-434b-a267-6a327c73888f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "2.9.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "# 1._ IMPORTAMOS KERAS\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.keras.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
      ],
      "metadata": {
        "id": "lOjhns67D4MP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28,28,1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28,28,1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVqgKKaeD77i",
        "outputId": "1c479bf5-05c7-4ec0-d028-b14de5126aa0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el Modelo de red neuronal CNN con:\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# La red será secuencial (de la entrada a la salida sin ciclos).\n",
        "model = Sequential()\n",
        "#En la primera capa convolucional hay 32 filtros , el tamaño de la ventana es de 5x5 y la función de activación relu.\n",
        "model.add(Conv2D(32, (5, 5), activation='relu',input_shape=(28,28,1)))\n",
        "#La de pooling correspondiente es de 2x2\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# En la segunda capa convolucional hay 64 filtros,el tamaño de la ventana es de 5x5 y la función de activación es relu.\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "# La de pooling correspondiente es de 2x2\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "#Capa Flatten\n",
        "model.add(Flatten())\n",
        "# Como tenemos 10 categorías, la última capa tiene que tener 10 neuronas y la función de activación debe ser\n",
        "# softmax ya que queremos que nos devuelva una distribución de probabilidad sobre las 10 clases.\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Resultado del summary:\n",
        "#832=((5x5)+1)x32 (filtros)\n",
        "#51264=((25x32)+1)x64 (filtros)\n",
        "#10250=1024(capa Flatten aplana (4x4x64)) x10 + 10(cada bias)\n",
        "# 832+51264+10250=62346(total de parámetros entrenables)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQe0vvcIEEW-",
        "outputId": "e9a6335e-ffc2-4a4f-e42e-4969581815d9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 12, 12, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,346\n",
            "Trainable params: 62,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilamos el modelo\n",
        "model.compile(loss='sparse_categorical_crossentropy', #la función de pérdida \n",
        "              optimizer='sgd',# cargamos el optimizador 'sgd' (Stocastic Gradient Descendent)\n",
        "              metrics=['accuracy']) # la métrica es 'accuracy': Solo tendremos en cuenta la fracción de imágenes que son\n",
        "                                    # correctamente clasificadas \n",
        "                                    \n",
        "\n"
      ],
      "metadata": {
        "id": "iqD4sUIOELxH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 15:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n"
      ],
      "metadata": {
        "id": "-Gi1N5iRGmoL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)"
      ],
      "metadata": {
        "id": "WcXSHhkKF9YM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutamos el entrenamiento \n",
        "# epochs: Épocas:\"una pasada sobre todo el conjunto de datos\",separara el entrenamiento en distintas fases para el registro y la evaluación periódica.\n",
        "#En cada iteración, la red calculará los gradientes de los pesos y ajustará los pesos \n",
        "#Al final de las iteraciones veremos que la red es capaz de clasificar las\n",
        "model.fit(train_images, train_labels, epochs=25, callbacks=[callback])\n",
        "#Verificamos el modelo ya entrenado contra el conjunto de prueba\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXCymMtVEOqS",
        "outputId": "45191259-749b-430c-c071-d6dd28a7d915"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8296 - accuracy: 0.7040 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5241 - accuracy: 0.8113 - lr: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4569 - accuracy: 0.8378 - lr: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4201 - accuracy: 0.8509 - lr: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3942 - accuracy: 0.8606 - lr: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3769 - accuracy: 0.8649 - lr: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3601 - accuracy: 0.8715 - lr: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3485 - accuracy: 0.8761 - lr: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3369 - accuracy: 0.8801 - lr: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3271 - accuracy: 0.8842 - lr: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3188 - accuracy: 0.8855 - lr: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3095 - accuracy: 0.8888 - lr: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3020 - accuracy: 0.8934 - lr: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2953 - accuracy: 0.8951 - lr: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2885 - accuracy: 0.8974 - lr: 0.0100\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.009048373438417912.\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2811 - accuracy: 0.9001 - lr: 0.0090\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.008187306113541126.\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2740 - accuracy: 0.9025 - lr: 0.0082\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0074081807397305965.\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2685 - accuracy: 0.9050 - lr: 0.0074\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00670319888740778.\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2630 - accuracy: 0.9062 - lr: 0.0067\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.006065304856747389.\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2575 - accuracy: 0.9085 - lr: 0.0061\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.005488114431500435.\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2537 - accuracy: 0.9097 - lr: 0.0055\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.004965851083397865.\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2500 - accuracy: 0.9120 - lr: 0.0050\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.004493287764489651.\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2468 - accuracy: 0.9125 - lr: 0.0045\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0040656947530806065.\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2435 - accuracy: 0.9135 - lr: 0.0041\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0036787926219403744.\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2401 - accuracy: 0.9146 - lr: 0.0037\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2874 - accuracy: 0.8985\n",
            "Test accuracy: 0.8985000252723694\n"
          ]
        }
      ]
    }
  ]
}